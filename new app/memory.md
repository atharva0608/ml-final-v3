# CloudOptim â€“ Agentless Kubernetes Cost Optimization (CAST AI Competitor)

**Last Updated**: 2025-11-28
**Status**: Architecture Defined - Ready for Implementation
**Architecture**: Agentless (EventBridge + SQS + Remote Kubernetes API)

---

## ğŸ¯ High-Level Goal

Build a **CAST AI competitor** that:
- âŒ **NO AGENTS** - No DaemonSets, no client-side components
- âœ… **Remote Kubernetes API** - Direct API calls to customer clusters
- âœ… **AWS EventBridge + SQS** - For Spot interruption warnings (2-minute notices)
- âœ… **Public Spot Advisor Data** - No customer data needed for Day Zero
- âœ… **Inference-Only ML Server** - Upload pre-trained models, no training on production

---

## ğŸ—ï¸ Two-Server Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Customer AWS Account                          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   EKS Cluster    â”‚        â”‚  EventBridge Rule  â”‚          â”‚
â”‚  â”‚                  â”‚        â”‚  + SQS Queue       â”‚          â”‚
â”‚  â”‚  (No agent!)     â”‚        â”‚                    â”‚          â”‚
â”‚  â”‚                  â”‚        â”‚  Spot interruption â”‚          â”‚
â”‚  â”‚  Workloads       â”‚        â”‚  warnings          â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â–²                              â”‚                      â”‚
â”‚         â”‚ K8s API (remote)             â”‚ SQS polling         â”‚
â”‚         â”‚                              â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â”‚                              â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚                                           â”‚
    â”‚  CloudOptim Control Plane                â”‚
    â”‚                                           â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚     Core Platform (Port 8000)       â”‚ â”‚
    â”‚  â”‚  â€¢ Central Backend (FastAPI)        â”‚ â”‚
    â”‚  â”‚  â€¢ PostgreSQL Database              â”‚ â”‚
    â”‚  â”‚  â€¢ Admin Frontend (React)           â”‚ â”‚
    â”‚  â”‚  â€¢ EventBridge/SQS Polling          â”‚ â”‚
    â”‚  â”‚  â€¢ Remote K8s API Client            â”‚ â”‚
    â”‚  â”‚  â€¢ AWS EC2 API Client               â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚                 â”‚ REST API                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚     ML Server (Port 8001+3001)      â”‚ â”‚
    â”‚  â”‚  â€¢ ML Backend (FastAPI)             â”‚ â”‚
    â”‚  â”‚  â€¢ PostgreSQL Database (pricing)    â”‚ â”‚
    â”‚  â”‚  â€¢ ML Frontend (React)              â”‚ â”‚
    â”‚  â”‚  â€¢ Model Hosting (inference-only)  â”‚ â”‚
    â”‚  â”‚  â€¢ Decision Engines (pluggable)    â”‚ â”‚
    â”‚  â”‚  â€¢ Data Gap Filler                 â”‚ â”‚
    â”‚  â”‚  â€¢ Pricing Data Fetcher            â”‚ â”‚
    â”‚  â”‚  â€¢ Redis Cache (Spot Advisor)      â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Key Features (CAST AI Parity)

### 1. Spot Instance Arbitrage with Fallback
**How It Works**:
- Uses **AWS Spot Advisor** public data (no customer data needed)
- Risk scoring formula:
  ```
  Risk Score = (0.60 Ã— Public_Rate) +
               (0.25 Ã— Volatility) +
               (0.10 Ã— Gap_Score) +
               (0.05 Ã— Time_Score)
  ```
- Automatic fallback to on-demand on interruption
- Receives 2-minute warnings via **EventBridge â†’ SQS**

**Data Source**: `https://spot-bid-advisor.s3.amazonaws.com/spot-advisor-data.json`

### 2. Bin Packing (Tetris Engine)
**How It Works**:
- Consolidates workloads to minimize node count
- Rebalances cluster to free up underutilized nodes
- Terminates empty nodes automatically
- Defragmentation runs every 10 minutes

**Day Zero**: Works immediately using Kubernetes Metrics API (remote)

### 3. Rightsizing
**Node-Level**:
- Replaces oversized nodes with smaller instances
- Monitors CPU/memory utilization via remote Metrics API
- Deterministic lookup tables (no ML needed for Day Zero)

**Workload-Level**:
- Suggests CPU/memory request adjustments for deployments
- Uses 95th percentile of actual usage over 7 days

### 4. Office Hours Scheduler
**How It Works**:
- Auto-scale dev/staging clusters to zero during off-hours
- Schedule: 9 AM - 6 PM weekdays, scale down after hours
- Scale back up before business hours
- Saves ~65% on non-production environments

### 5. Zombie Volume Cleanup
**How It Works**:
- Detects EBS volumes not attached to any instance
- Checks if PVC still exists in Kubernetes
- Deletes orphaned volumes after 7-day grace period
- Typical savings: 5-10% of storage costs

### 6. Network Traffic Optimization
**How It Works**:
- Analyzes cross-AZ traffic patterns
- Places pods with affinity rules to minimize cross-AZ traffic
- Saves on AWS data transfer costs (cross-AZ = $0.01/GB)

### 7. OOMKilled Auto-Remediation
**How It Works**:
- Detects pods killed due to out-of-memory
- Automatically increases memory requests by 20%
- Redeploys pod with updated resource requests
- Prevents future OOM crashes

### 8. Ghost Probe Scanner
**How It Works**:
- Scans AWS account for running EC2 instances **not in Kubernetes**
- Identifies "ghost" instances (zombie instances left behind)
- Flags for manual review or auto-terminates after 24 hours
- Day Zero compatible: no historical data needed

---

## ğŸ”§ Agentless Architecture Details

### Remote Kubernetes API Access
**No DaemonSets Needed**:
- Customer provides kubeconfig (service account token)
- CloudOptim makes **remote API calls** to K8s API server:
  ```
  GET /api/v1/nodes
  GET /api/v1/pods
  GET /apis/metrics.k8s.io/v1beta1/nodes
  POST /api/v1/namespaces/{ns}/pods/{pod}/eviction
  PATCH /api/v1/nodes/{name}
  ```

**RBAC Permissions Required**:
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cloudoptim
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cloudoptim
rules:
  - apiGroups: [""]
    resources: ["nodes", "pods", "persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: ["apps"]
    resources: ["deployments", "statefulsets"]
    verbs: ["get", "list", "patch"]
  - apiGroups: ["metrics.k8s.io"]
    resources: ["nodes", "pods"]
    verbs: ["get", "list"]
  - apiGroups: [""]
    resources: ["pods/eviction"]
    verbs: ["create"]
```

### AWS EventBridge + SQS Integration
**Spot Interruption Warnings**:
1. Customer creates EventBridge rule in their AWS account:
   ```json
   {
     "source": ["aws.ec2"],
     "detail-type": ["EC2 Spot Instance Interruption Warning"],
     "detail": {
       "instance-id": [{"prefix": ""}]
     }
   }
   ```
2. Rule sends events to SQS queue
3. CloudOptim polls SQS queue every 5 seconds
4. Receives 2-minute warning before Spot termination
5. Drains node and launches replacement immediately

**SQS Message Format**:
```json
{
  "version": "0",
  "id": "12345",
  "detail-type": "EC2 Spot Instance Interruption Warning",
  "source": "aws.ec2",
  "time": "2025-11-28T10:00:00Z",
  "detail": {
    "instance-id": "i-1234567890abcdef0",
    "instance-action": "terminate"
  }
}
```

### AWS API Integration (EC2)
**No Customer Data Needed**:
- Launch/terminate instances via EC2 API
- Query Spot prices: `DescribeSpotPriceHistory`
- All done remotely, no agents

**IAM Permissions Required**:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "ec2:RunInstances",
        "ec2:TerminateInstances",
        "ec2:DescribeInstances",
        "ec2:DescribeSpotPriceHistory",
        "ec2:CreateTags"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "sqs:ReceiveMessage",
        "sqs:DeleteMessage",
        "sqs:GetQueueAttributes"
      ],
      "Resource": "arn:aws:sqs:*:*:cloudoptim-*"
    }
  ]
}
```

---

## ğŸ”¬ ML Server Infrastructure (Complete Stack)

### ML Backend (FastAPI + PostgreSQL + Redis)

**Purpose**: Complete ML data management and inference infrastructure

**Components**:
1. **FastAPI Backend** (Port 8001):
   - Model upload & management API
   - Data gap filling API
   - Model refresh API (trigger data fetch & model reload)
   - Pricing data API (Spot prices, On-Demand prices, Spot Advisor)
   - Prediction & decision API
   - Health & metrics API

2. **PostgreSQL Database** (dedicated ML database):
   - **ml_models**: Model metadata, versions, trained_until_date
   - **decision_engines**: Engine metadata, versions, configs
   - **spot_prices**: Historical Spot prices (indexed by instance_type, region, timestamp)
   - **on_demand_prices**: On-Demand pricing data
   - **spot_advisor_data**: AWS Spot Advisor interruption rates (public data)
   - **data_gaps**: Gap analysis records, fill progress tracking
   - **model_refresh_history**: Model refresh execution logs
   - **predictions_log**: Prediction history for monitoring
   - **decision_execution_log**: Decision execution history

3. **Redis Cache**:
   - AWS Spot Advisor data (refresh every 1 hour)
   - Recent Spot prices (last 7 days for fast lookups)
   - Active model metadata
   - Recent predictions (5-minute TTL)

### ML Frontend (React Dashboard - Port 3001)

**Purpose**: Complete ML lifecycle management interface

**Pages**:
1. **Model Management**:
   - Upload models (.pkl files)
   - Activate/deactivate model versions
   - View model details, performance metrics
   - Model version history

2. **Data Gap Filler**:
   - Visual gap analyzer (timeline view)
   - Gap fill configuration (instance types, regions, date ranges)
   - Real-time progress tracking (progress bar, ETA, records filled)
   - Gap-filling history

3. **Pricing Data Viewer**:
   - Spot price charts (interactive, filterable)
   - On-Demand price comparison
   - Spot Advisor heatmap (interruption rates by instance type Ã— region)
   - Export to CSV

4. **Model Refresh Dashboard**:
   - Trigger manual refresh ("Fetch data from [date] to [date]")
   - Select instance types (with pattern matching: "m5.*", "c5.*")
   - Select regions (multi-select)
   - Real-time refresh progress
   - Auto-refresh scheduler (daily/weekly at specific time)
   - Refresh history

5. **Live Predictions**:
   - Real-time prediction charts
   - Prediction vs Actual comparison
   - Confidence score metrics
   - Prediction stream (live updates via WebSocket)

6. **Decision Engine Dashboard**:
   - Upload decision engines (.py files)
   - Engine configuration (JSON editor)
   - Test engines with sample data
   - Live decision stream
   - Decision history

### Key Workflows

**Workflow 1: Model Upload â†’ Gap Fill â†’ Activate**:
```
1. User uploads model via ML Frontend
   â†’ Backend saves to /models/uploaded/, inserts into ml_models table

2. User clicks "Analyze Gap"
   â†’ Backend compares trained_until_date vs current_date
   â†’ Returns: gap_days=28, estimated_records=150,000

3. User configures gap fill:
   - Instance types: m5.*, c5.*, r5.*
   - Regions: us-east-1, us-west-2
   - Click "Fill Gap"

4. Backend starts gap-filling task:
   â†’ Fetches Spot prices from AWS DescribeSpotPriceHistory
   â†’ Inserts into spot_prices table in batches
   â†’ Frontend polls progress every 2 seconds

5. Gap filled â†’ User activates model
   â†’ Model now has up-to-date pricing data
   â†’ Ready for predictions
```

**Workflow 2: Model Refresh (Scheduled)**:
```
1. Cron scheduler (daily at 2 AM UTC):
   â†’ Triggers refresh for active models

2. Backend refresh service:
   â†’ Fetches last 7 days of Spot prices
   â†’ Updates spot_prices table
   â†’ Updates spot_advisor_data from AWS Spot Advisor JSON

3. Reloads model with fresh data
   â†’ Updates model metadata: last_refresh_date
   â†’ Records in model_refresh_history

4. If auto_activate=true:
   â†’ Activates refreshed model automatically

5. Frontend shows notification:
   â†’ "Model Refreshed - Data coverage: [dates]"
```

**Workflow 3: Live Prediction Request (from Core Platform)**:
```
1. Core Platform â†’ ML Server: POST /api/v1/ml/decision/spot-optimize
   â†’ Body: ClusterState, requirements, constraints

2. ML Backend queries database:
   SELECT * FROM spot_prices
   WHERE instance_type IN (...) AND region = '...'
     AND timestamp > NOW() - INTERVAL '7 days'
   ORDER BY timestamp DESC LIMIT 1000

   SELECT * FROM spot_advisor_data
   WHERE instance_type IN (...) AND region = '...'

3. Loads active model, runs inference

4. Passes to decision engine, generates recommendations

5. Returns DecisionResponse to Core Platform

6. Logs prediction & decision in database

7. ML Frontend updates live dashboard (WebSocket)
```

### API Highlights

**Model Management**:
- `POST /api/v1/ml/models/upload` - Upload model
- `GET /api/v1/ml/models/list` - List models
- `POST /api/v1/ml/models/activate` - Activate version
- `GET /api/v1/ml/models/{id}/details` - Model details

**Data Gap Filling**:
- `POST /api/v1/ml/gap-filler/analyze` - Analyze gaps
- `POST /api/v1/ml/gap-filler/fill` - Fill gaps
- `GET /api/v1/ml/gap-filler/status/{id}` - Fill progress
- `GET /api/v1/ml/gap-filler/history` - Fill history

**Model Refresh**:
- `POST /api/v1/ml/refresh/trigger` - Trigger refresh
- `GET /api/v1/ml/refresh/status/{id}` - Refresh progress
- `GET /api/v1/ml/refresh/history` - Refresh history
- `POST /api/v1/ml/refresh/schedule` - Schedule auto-refresh

**Pricing Data**:
- `GET /api/v1/ml/pricing/spot` - Spot price history
- `GET /api/v1/ml/pricing/on-demand` - On-Demand prices
- `GET /api/v1/ml/pricing/spot-advisor` - Spot Advisor data
- `POST /api/v1/ml/pricing/fetch` - Manual data fetch
- `GET /api/v1/ml/pricing/stats` - Data coverage stats

---

## ğŸ“ Repository Structure

```
new app/
â”œâ”€â”€ memory.md                   # This file
â”œâ”€â”€ ml-server/                  # ML Server (Backend + Database + Frontend)
â”‚   â”œâ”€â”€ SESSION_MEMORY.md      # ML server comprehensive documentation
â”‚   â”œâ”€â”€ backend/                # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI entry point
â”‚   â”‚   â”œâ”€â”€ api/routes/        # API endpoints (models, engines, gap-filler, refresh, pricing)
â”‚   â”‚   â”œâ”€â”€ database/          # SQLAlchemy models, Pydantic schemas, migrations
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic (model, engine, pricing, gap-filler, refresh services)
â”‚   â”‚   â””â”€â”€ utils/             # Validators, helpers
â”‚   â”œâ”€â”€ ml-frontend/            # React ML Dashboard (Port 3001)
â”‚   â”‚   â”œâ”€â”€ src/components/    # Model management, gap filler, pricing viewer, refresh dashboard
â”‚   â”‚   â”œâ”€â”€ src/services/      # API client
â”‚   â”‚   â””â”€â”€ src/types/         # TypeScript types
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ spot_predictor.py  # ML models
â”‚   â”‚   â””â”€â”€ uploaded/          # Uploaded model files (.pkl)
â”‚   â”œâ”€â”€ decision_engine/
â”‚   â”‚   â”œâ”€â”€ spot_optimizer.py  # Decision engines
â”‚   â”‚   â””â”€â”€ uploaded/          # Uploaded engine files (.py)
â”‚   â”œâ”€â”€ config/                 # ML config, database config
â”‚   â”œâ”€â”€ scripts/                # install.sh, setup_database.sh, start_backend.sh, start_frontend.sh
â”‚   â””â”€â”€ tests/                  # API tests, service tests
â”œâ”€â”€ core-platform/              # Central backend, DB, admin UI
â”‚   â”œâ”€â”€ SESSION_MEMORY.md      # Core platform documentation
â”‚   â”œâ”€â”€ api/                    # Main REST API
â”‚   â”œâ”€â”€ database/               # PostgreSQL schema & migrations
â”‚   â”œâ”€â”€ admin-frontend/         # React admin dashboard (Port 3000)
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â”‚   â”œâ”€â”€ eventbridge_poller.py   # SQS poller for Spot warnings
â”‚   â”‚   â”œâ”€â”€ k8s_remote_client.py    # Remote K8s API client
â”‚   â”‚   â”œâ”€â”€ spot_handler.py         # Spot interruption handler
â”‚   â”‚   â”œâ”€â”€ ghost_probe_scanner.py  # Zombie instance scanner
â”‚   â”‚   â””â”€â”€ volume_cleanup.py       # Zombie volume cleanup
â”‚   â””â”€â”€ ...
â”œâ”€â”€ common/                     # Shared components
â”‚   â”œâ”€â”€ INTEGRATION_GUIDE.md   # Integration documentation
â”‚   â”œâ”€â”€ schemas/                # Pydantic models (shared between servers)
â”‚   â”œâ”€â”€ auth/                   # Authentication
â”‚   â””â”€â”€ config/                 # Common configuration
â””â”€â”€ infra/                      # Infrastructure as Code
    â”œâ”€â”€ docker-compose.yml      # Local development (all services)
    â”œâ”€â”€ kubernetes/             # K8s manifests
    â””â”€â”€ terraform/              # Cloud infrastructure
```

---

## ğŸ”— API Endpoints

### ML Server (Port 8001)
```http
# Model Management
POST /api/v1/ml/models/upload       - Upload pre-trained model
GET  /api/v1/ml/models/list         - List models
POST /api/v1/ml/models/activate     - Activate model version

# Decision Engines
POST /api/v1/ml/engines/upload      - Upload decision engine
GET  /api/v1/ml/engines/list        - List engines
POST /api/v1/ml/engines/select      - Select active engine

# Gap Filling
POST /api/v1/ml/gap-filler/analyze  - Analyze data gaps
POST /api/v1/ml/gap-filler/fill     - Fill gaps with AWS data

# Predictions & Decisions
POST /api/v1/ml/predict/spot-interruption  - Predict interruption
POST /api/v1/ml/decision/spot-optimize     - Spot optimization
POST /api/v1/ml/decision/bin-pack          - Bin packing
POST /api/v1/ml/decision/rightsize         - Rightsizing
```

### Core Platform (Port 8000)
```http
# Customer & Cluster Management
GET  /api/v1/admin/clusters         - List clusters
POST /api/v1/admin/clusters         - Register new cluster
GET  /api/v1/admin/savings          - Real-time savings

# Optimization
POST /api/v1/optimization/trigger   - Trigger optimization
GET  /api/v1/optimization/history   - Optimization history

# EventBridge Integration
GET  /api/v1/events/spot-warnings   - Recent Spot warnings
POST /api/v1/events/process         - Process Spot event manually

# Remote Kubernetes Operations
GET  /api/v1/k8s/{cluster_id}/nodes         - Get cluster nodes
POST /api/v1/k8s/{cluster_id}/nodes/drain   - Drain node
POST /api/v1/k8s/{cluster_id}/nodes/cordon  - Cordon node
```

---

## ğŸ“Š Day Zero Operation (No Customer Data)

CloudOptim works **immediately** without historical data:

### 1. Spot Advisor Data (Public)
- Download from AWS: `spot-advisor-data.json`
- Contains interruption rates for all instance types
- Updated by AWS, publicly available
- **No customer data needed**

### 2. Ghost Probe Scanner
- Scans customer AWS account for EC2 instances
- Cross-references with Kubernetes nodes
- Identifies zombie instances immediately
- **No historical data needed**

### 3. Rightsizing (Deterministic)
- Uses lookup tables for common workload patterns
- Reads current metrics from Kubernetes Metrics API
- Makes recommendations based on current state
- **No historical data needed**

### 4. Bin Packing
- Uses current pod scheduling data from K8s API
- Simulates rebalancing scenarios
- Finds optimal consolidation immediately
- **No historical data needed**

---

## ğŸ”„ Inference-Only ML Server

### Model Upload Flow
1. User uploads pre-trained model (`.pkl` file) via admin UI
2. ML server stores model in `/models/uploaded/{model_id}.pkl`
3. Extracts metadata (trained_until date)
4. User triggers gap-fill if needed
5. ML server activates model for predictions

### Gap-Filling Process
**Problem**: Model trained on October data, need predictions for November
**Solution**:
1. ML server detects gap (trained_until â†’ today)
2. Automatically fetches historic Spot prices from AWS API
3. Fills feature engineering pipeline with historic data
4. Model ready for up-to-date predictions immediately

### Decision Engine (Pluggable)
- Upload Python modules via frontend
- Fixed input format (metrics, prices, states)
- Fixed output format (actions, scores, explanations)
- Hot-swap engines without downtime
- A/B test different decision strategies

---

## ğŸ“ Configuration

### Core Platform Environment Variables
```bash
# Server
CENTRAL_SERVER_HOST=0.0.0.0
CENTRAL_SERVER_PORT=8000

# Database
DB_HOST=postgres.internal
DB_PORT=5432
DB_NAME=cloudoptim
DB_USER=cloudoptim
DB_PASSWORD=xxx

# Redis
REDIS_HOST=redis.internal
REDIS_PORT=6379

# ML Server
ML_SERVER_URL=http://ml-server:8001
ML_SERVER_API_KEY=xxx

# AWS
AWS_REGION=us-east-1

# EventBridge/SQS Polling
SQS_POLL_INTERVAL_SECONDS=5
SQS_MAX_MESSAGES=10
SQS_VISIBILITY_TIMEOUT=30

# Kubernetes Remote API
K8S_API_TIMEOUT_SECONDS=30
K8S_API_RETRY_ATTEMPTS=3
```

### ML Server Environment Variables
```bash
# Server
ML_SERVER_HOST=0.0.0.0
ML_SERVER_PORT=8001

# Models
MODEL_UPLOAD_DIR=/app/models/uploaded
ALLOW_MODEL_TRAINING=false  # Explicitly disabled

# Gap Filler
GAP_FILLER_ENABLED=true
GAP_FILLER_AWS_REGION=us-east-1
GAP_FILLER_HISTORIC_DAYS_MAX=90

# Decision Engines
DECISION_ENGINE_DIR=/app/engines
DECISION_ENGINE_ACTIVE=spot_optimizer_v1

# Storage
REDIS_HOST=redis.internal
REDIS_PORT=6379

# Central Platform
CENTRAL_PLATFORM_URL=http://core-platform:8000
CENTRAL_PLATFORM_API_KEY=xxx
```

---

## ğŸ¯ Implementation Roadmap

### Phase 1: Core Infrastructure
- [ ] Setup PostgreSQL database schema
- [ ] Create FastAPI server for core platform
- [ ] Implement remote Kubernetes API client
- [ ] Setup EventBridge/SQS polling service

### Phase 2: ML Server
- [ ] Create ML server with FastAPI
- [ ] Implement model upload endpoints
- [ ] Create data gap filler with AWS integration
- [ ] Implement decision engine registry

### Phase 3: Features
- [ ] Spot arbitrage with risk scoring
- [ ] Bin packing engine
- [ ] Rightsizing engine
- [ ] Office hours scheduler
- [ ] Zombie volume cleanup
- [ ] Network optimization
- [ ] OOMKilled remediation
- [ ] Ghost probe scanner

### Phase 4: Admin Frontend
- [ ] Create React admin dashboard
- [ ] Model upload UI
- [ ] Live cost monitoring
- [ ] Prediction vs actual charts
- [ ] Cluster management UI
- [ ] Optimization history

### Phase 5: Testing & Production
- [ ] Integration testing
- [ ] Load testing
- [ ] Security audit
- [ ] Production deployment
- [ ] Documentation

---

## ğŸ” Security Considerations

### Customer Onboarding
1. Customer creates IAM role with CloudOptim trust policy
2. Customer creates EventBridge rule + SQS queue
3. Customer creates Kubernetes service account + RBAC
4. Customer provides:
   - AWS IAM Role ARN
   - SQS Queue URL
   - Kubernetes API endpoint
   - Kubernetes service account token

### Data Security
- All communication over HTTPS/TLS
- No customer data leaves their account
- CloudOptim only makes API calls, doesn't store workload data
- Service account tokens encrypted at rest
- IAM roles follow least-privilege principle

---

**Last Updated**: 2025-11-28
**Status**: Ready for implementation
**Architecture**: Agentless (No DaemonSets, remote API only)
