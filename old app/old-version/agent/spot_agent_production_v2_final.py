"""
AWS Spot Optimizer - Agent Backend v3.2.0 (PRODUCTION READY)
===========================================================================
FIXES ALL AGENT-SIDE ISSUES + FULL COMPATIBILITY WITH SERVER v2.3.0

Agent-Side Fixes Implemented:
âœ“ #2: Logical agent identity preservation (no duplicate agents)
âœ“ #3: Accurate instance mode detection with dual verification
âœ“ #4: Fast manual override execution (15s polling, priority queue)
âœ“ #6: Real-time heartbeat with accurate status reporting
âœ“ #8: Single active instance enforcement
âœ“ #9: Proper auto-terminate with confirmation
âœ“ #10: Working disable toggle with immediate effect
âœ“ #11: Fast switch action updates (15s check interval)
âœ“ FIX: Price data fetching with VPC support and robust fallbacks
âœ“ FIX: On-demand price caching for accurate savings calculations
âœ“ FIX: Enhanced command validation and error handling
âœ“ FIX: Improved switching logic with detailed logging

Key Features:
- Dual mode verification (AWS API + Instance Metadata)
- Priority-based command execution
- Graceful shutdown with cleanup
- Comprehensive error handling
- Detailed switch timing tracking
- Memory-efficient operation
- Robust price data collection with VPC product description support
- Cached on-demand pricing for savings tracking
- Enhanced debugging with detailed logging
===========================================================================
"""

import os
import sys
import time
import json
import socket
import signal
import logging
import requests
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from pathlib import Path
from urllib.parse import urljoin

import boto3
from botocore.exceptions import ClientError, BotoCoreError
from dotenv import load_dotenv

load_dotenv()

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('spot_optimizer_agent.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURATION
# ============================================================================

@dataclass
class AgentConfig:
    """Agent configuration with environment variable support"""
    
    # Server Connection
    SERVER_URL: str = os.getenv('SPOT_OPTIMIZER_SERVER_URL', 'http://localhost:5000')
    CLIENT_TOKEN: str = os.getenv('SPOT_OPTIMIZER_CLIENT_TOKEN', '')
    
    # Agent Identity (FIX #2: Logical agent ID for identity preservation)
    LOGICAL_AGENT_ID: str = os.getenv('LOGICAL_AGENT_ID', '')  # Set this to preserve identity across switches
    HOSTNAME: str = socket.gethostname()
    
    # AWS Configuration
    REGION: str = os.getenv('AWS_REGION', 'us-east-1')
    
    # Timing Configuration (FIX #4, #11: Fast polling for manual overrides)
    HEARTBEAT_INTERVAL: int = int(os.getenv('HEARTBEAT_INTERVAL', 30))  # 30 seconds
    PENDING_COMMANDS_CHECK_INTERVAL: int = int(os.getenv('PENDING_COMMANDS_CHECK_INTERVAL', 15))  # 15 seconds
    CONFIG_REFRESH_INTERVAL: int = int(os.getenv('CONFIG_REFRESH_INTERVAL', 60))  # 60 seconds
    PRICING_REPORT_INTERVAL: int = int(os.getenv('PRICING_REPORT_INTERVAL', 300))  # 5 minutes
    
    # Switch Configuration (FIX #9: Auto-terminate settings)
    AUTO_TERMINATE_OLD_INSTANCE: bool = os.getenv('AUTO_TERMINATE_OLD_INSTANCE', 'true').lower() == 'true'
    TERMINATE_WAIT_TIME: int = int(os.getenv('TERMINATE_WAIT_TIME', 300))  # 5 minutes
    CREATE_SNAPSHOT_ON_SWITCH: bool = os.getenv('CREATE_SNAPSHOT_ON_SWITCH', 'true').lower() == 'true'
    
    # Agent Version
    AGENT_VERSION: str = '3.2.0'
    
    def validate(self) -> bool:
        """Validate required configuration"""
        if not self.CLIENT_TOKEN:
            logger.error("CLIENT_TOKEN not set!")
            return False
        if not self.SERVER_URL:
            logger.error("SERVER_URL not set!")
            return False
        if not self.LOGICAL_AGENT_ID:
            logger.warning("LOGICAL_AGENT_ID not set. Will use instance ID as logical ID.")
        return True

config = AgentConfig()

# ============================================================================
# AWS CLIENTS
# ============================================================================

class AWSClients:
    """Singleton AWS client manager"""
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialize()
        return cls._instance
    
    def _initialize(self):
        """Initialize AWS clients"""
        try:
            self.ec2 = boto3.client('ec2', region_name=config.REGION)
            self.ec2_resource = boto3.resource('ec2', region_name=config.REGION)
            logger.info(f"âœ“ AWS clients initialized (region: {config.REGION})")
        except Exception as e:
            logger.error(f"Failed to initialize AWS clients: {e}")
            raise

aws_clients = AWSClients()

# ============================================================================
# INSTANCE METADATA & MODE DETECTION
# ============================================================================

class InstanceMetadata:
    """FIX #3: Accurate instance mode detection with dual verification"""
    
    METADATA_BASE_URL = "http://169.254.169.254/latest"
    METADATA_TIMEOUT = 2
    
    @staticmethod
    def get_metadata(path: str) -> Optional[str]:
        """Fetch instance metadata"""
        try:
            # Use IMDSv2 token-based auth
            token_response = requests.put(
                f"{InstanceMetadata.METADATA_BASE_URL}/api/token",
                headers={"X-aws-ec2-metadata-token-ttl-seconds": "21600"},
                timeout=InstanceMetadata.METADATA_TIMEOUT
            )
            token = token_response.text
            
            response = requests.get(
                f"{InstanceMetadata.METADATA_BASE_URL}/{path}",
                headers={"X-aws-ec2-metadata-token": token},
                timeout=InstanceMetadata.METADATA_TIMEOUT
            )
            response.raise_for_status()
            return response.text
        except Exception as e:
            logger.debug(f"Metadata fetch failed for {path}: {e}")
            return None
    
    @staticmethod
    def get_instance_id() -> str:
        """Get current instance ID"""
        instance_id = InstanceMetadata.get_metadata("meta-data/instance-id")
        if not instance_id:
            raise RuntimeError("Cannot determine instance ID from metadata")
        return instance_id
    
    @staticmethod
    def get_instance_type() -> str:
        """Get instance type"""
        return InstanceMetadata.get_metadata("meta-data/instance-type") or "unknown"
    
    @staticmethod
    def get_availability_zone() -> str:
        """Get availability zone"""
        return InstanceMetadata.get_metadata("meta-data/placement/availability-zone") or "unknown"
    
    @staticmethod
    def get_ami_id() -> str:
        """Get AMI ID"""
        return InstanceMetadata.get_metadata("meta-data/ami-id") or "unknown"
    
    @staticmethod
    def detect_instance_mode_metadata() -> str:
        """
        FIX #3: Detect mode from instance metadata
        Returns: 'spot' or 'ondemand'
        """
        try:
            # Check spot instance action (only exists for spot)
            spot_action = InstanceMetadata.get_metadata("meta-data/spot/instance-action")
            if spot_action is not None:
                return 'spot'
            
            # Check instance lifecycle
            lifecycle = InstanceMetadata.get_metadata("meta-data/instance-life-cycle")
            if lifecycle == 'spot':
                return 'spot'
            elif lifecycle == 'on-demand':
                return 'ondemand'
            
            # Default to on-demand if no spot indicators
            return 'ondemand'
        except Exception as e:
            logger.warning(f"Metadata mode detection failed: {e}")
            return 'unknown'
    
    @staticmethod
    def detect_instance_mode_api(instance_id: str) -> str:
        """
        FIX #3: Detect mode from AWS EC2 API
        More reliable than metadata
        """
        try:
            response = aws_clients.ec2.describe_instances(InstanceIds=[instance_id])
            
            if not response['Reservations']:
                return 'unknown'
            
            instance = response['Reservations'][0]['Instances'][0]
            
            # Check instance lifecycle
            lifecycle = instance.get('InstanceLifecycle', 'normal')
            
            if lifecycle == 'spot':
                return 'spot'
            elif lifecycle == 'normal' or lifecycle == 'scheduled':
                return 'ondemand'
            
            return 'unknown'
        except Exception as e:
            logger.warning(f"API mode detection failed: {e}")
            return 'unknown'
    
    @staticmethod
    def detect_instance_mode_dual() -> Tuple[str, str]:
        """
        FIX #3: Dual verification of instance mode
        Returns: (metadata_mode, api_mode)
        """
        instance_id = InstanceMetadata.get_instance_id()
        
        metadata_mode = InstanceMetadata.detect_instance_mode_metadata()
        api_mode = InstanceMetadata.detect_instance_mode_api(instance_id)
        
        if metadata_mode != api_mode and metadata_mode != 'unknown' and api_mode != 'unknown':
            logger.warning(f"Mode mismatch! Metadata={metadata_mode}, API={api_mode}")
        
        # Prefer API mode as it's more reliable
        final_mode = api_mode if api_mode != 'unknown' else metadata_mode
        
        return final_mode, api_mode

# ============================================================================
# SERVER API CLIENT
# ============================================================================

class ServerAPI:
    """API client for central server communication"""
    
    def __init__(self):
        self.base_url = config.SERVER_URL
        self.session = requests.Session()
        self.session.headers.update({
            'Authorization': f'Bearer {config.CLIENT_TOKEN}',
            'Content-Type': 'application/json'
        })
    
    def _make_request(self, method: str, endpoint: str, **kwargs) -> Optional[Dict]:
        """Make HTTP request with error handling"""
        url = urljoin(self.base_url, endpoint)
        try:
            response = self.session.request(method, url, timeout=30, **kwargs)
            response.raise_for_status()
            return response.json() if response.text else {}
        except requests.exceptions.Timeout:
            logger.error(f"Request timeout: {endpoint}")
            return None
        except requests.exceptions.ConnectionError:
            logger.error(f"Connection error: {endpoint}")
            return None
        except requests.exceptions.HTTPError as e:
            # Enhanced logging for database connection pool issues
            if response.status_code == 500:
                error_text = response.text
                if 'pool exhausted' in error_text.lower() or 'failed getting connection' in error_text.lower():
                    logger.critical("=" * 80)
                    logger.critical("DATABASE CONNECTION POOL EXHAUSTED ON CENTRAL SERVER!")
                    logger.critical(f"Endpoint: {endpoint}")
                    logger.critical("This is a BACKEND ISSUE in the central server (final-ml repo)")
                    logger.critical("Action Required: Fix database connection pool configuration")
                    logger.critical("  1. Check database connection pool size (SQLALCHEMY_POOL_SIZE)")
                    logger.critical("  2. Check max overflow (SQLALCHEMY_MAX_OVERFLOW)")
                    logger.critical("  3. Check pool recycle time (SQLALCHEMY_POOL_RECYCLE)")
                    logger.critical("  4. Ensure database connections are properly closed")
                    logger.critical("=" * 80)
                else:
                    logger.error(f"HTTP error {response.status_code}: {endpoint} - {error_text}")
            else:
                logger.error(f"HTTP error {response.status_code}: {endpoint} - {response.text}")
            return None
        except Exception as e:
            logger.error(f"Request failed: {endpoint} - {e}")
            return None
    
    def register_agent(self, instance_info: Dict) -> Optional[Dict]:
        """Register agent with server"""
        return self._make_request('POST', '/api/agents/register', json=instance_info)
    
    def send_heartbeat(self, agent_id: str, status: str, monitored_instances: List[str]) -> bool:
        """Send heartbeat to server"""
        result = self._make_request(
            'POST',
            f'/api/agents/{agent_id}/heartbeat',
            json={
                'status': status,
                'monitored_instances': monitored_instances
            }
        )
        return result is not None
    
    def send_pricing_report(self, agent_id: str, report: Dict) -> bool:
        """Send pricing report to server"""
        result = self._make_request(
            'POST',
            f'/api/agents/{agent_id}/pricing-report',
            json=report
        )
        return result is not None
    
    def get_agent_config(self, agent_id: str) -> Optional[Dict]:
        """FIX #10: Get agent configuration (for enable/disable check)"""
        return self._make_request('GET', f'/api/agents/{agent_id}/config')
    
    def get_pending_commands(self, agent_id: str) -> List[Dict]:
        """FIX #4: Get pending commands with priority"""
        result = self._make_request('GET', f'/api/agents/{agent_id}/pending-commands')
        if not result:
            return []

        # Handle different response formats
        if isinstance(result, list):
            return result
        elif isinstance(result, dict):
            # Try common keys
            return result.get('commands', result.get('pending_commands', result.get('data', [])))

        logger.warning(f"Unexpected pending commands response format: {type(result)}")
        return []
    
    def mark_command_executed(self, agent_id: str, command_id: str) -> bool:
        """Mark command as executed"""
        result = self._make_request(
            'POST',
            f'/api/agents/{agent_id}/mark-command-executed',
            json={'command_id': command_id}
        )
        return result is not None
    
    def send_switch_report(self, agent_id: str, switch_data: Dict) -> bool:
        """FIX #9, #17: Send detailed switch report with timing"""
        result = self._make_request(
            'POST',
            f'/api/agents/{agent_id}/switch-report',
            json=switch_data
        )
        return result is not None

# ============================================================================
# SPOT PRICING COLLECTOR
# ============================================================================

class SpotPricingCollector:
    """Collect spot pricing data for pools"""
    
    def __init__(self):
        self.ec2 = aws_clients.ec2
    
    def get_spot_pools(self, instance_type: str, region: str) -> List[Dict]:
        """Get available spot pools for instance type"""
        try:
            response = self.ec2.describe_availability_zones(
                Filters=[{'Name': 'region-name', 'Values': [region]}]
            )
            
            zones = [z['ZoneName'] for z in response['AvailabilityZones'] if z['State'] == 'available']
            
            pools = []
            for az in zones:
                pool_id = f"{instance_type}.{az}"
                price = self._get_spot_price(instance_type, az)
                
                if price:
                    pools.append({
                        'pool_id': pool_id,
                        'instance_type': instance_type,
                        'az': az,
                        'price': price
                    })
            
            return pools
        except Exception as e:
            logger.error(f"Failed to get spot pools: {e}")
            return []
    
    def _get_spot_price(self, instance_type: str, az: str) -> Optional[float]:
        """Get current spot price for instance type in AZ"""
        try:
            # Try multiple product descriptions to ensure we get results
            # Most modern instances use VPC, so try that first
            product_descriptions = [
                'Linux/UNIX (Amazon VPC)',
                'Linux/UNIX'
            ]

            for product_desc in product_descriptions:
                try:
                    response = self.ec2.describe_spot_price_history(
                        InstanceTypes=[instance_type],
                        AvailabilityZone=az,
                        MaxResults=1,
                        ProductDescriptions=[product_desc]
                    )

                    if response['SpotPriceHistory']:
                        price = float(response['SpotPriceHistory'][0]['SpotPrice'])
                        logger.debug(f"Got spot price for {instance_type} in {az}: ${price} ({product_desc})")
                        return price
                except Exception as e:
                    logger.debug(f"Failed with {product_desc}: {e}")
                    continue

            # If no product description worked, try without the filter
            response = self.ec2.describe_spot_price_history(
                InstanceTypes=[instance_type],
                AvailabilityZone=az,
                MaxResults=1
            )

            if response['SpotPriceHistory']:
                price = float(response['SpotPriceHistory'][0]['SpotPrice'])
                product_desc = response['SpotPriceHistory'][0].get('ProductDescription', 'Unknown')
                logger.debug(f"Got spot price for {instance_type} in {az}: ${price} ({product_desc})")
                return price

            logger.warning(f"No spot price history found for {instance_type} in {az}")
            return None
        except Exception as e:
            logger.error(f"Failed to get spot price for {instance_type} in {az}: {e}")
            return None
    
    def get_ondemand_price(self, instance_type: str, region: str) -> float:
        """Get on-demand price (from pricing API or fallback)"""
        try:
            # Try to get from pricing API
            # NOTE: Pricing API is only available in us-east-1
            pricing = boto3.client('pricing', region_name='us-east-1')

            location = self._region_to_location(region)
            logger.info(f"Fetching on-demand price for {instance_type} in {location}...")

            # FIXED: Removed invalid 'capacitystatus' filter that was causing no results
            response = pricing.get_products(
                ServiceCode='AmazonEC2',
                Filters=[
                    {'Type': 'TERM_MATCH', 'Field': 'instanceType', 'Value': instance_type},
                    {'Type': 'TERM_MATCH', 'Field': 'location', 'Value': location},
                    {'Type': 'TERM_MATCH', 'Field': 'operatingSystem', 'Value': 'Linux'},
                    {'Type': 'TERM_MATCH', 'Field': 'tenancy', 'Value': 'Shared'},
                    {'Type': 'TERM_MATCH', 'Field': 'preInstalledSw', 'Value': 'NA'}
                ],
                MaxResults=1
            )

            if response['PriceList']:
                price_data = json.loads(response['PriceList'][0])
                terms = price_data['terms']['OnDemand']

                for term in terms.values():
                    for price_dim in term['priceDimensions'].values():
                        price = float(price_dim['pricePerUnit']['USD'])
                        logger.info(f"âœ“ Got on-demand price for {instance_type}: ${price}/hr")
                        return price

            logger.warning(f"No on-demand price found in pricing API for {instance_type} in {location}")

            # Fallback: estimate based on spot price
            logger.info("Attempting to estimate on-demand price from spot prices...")
            spot_pools = self.get_spot_pools(instance_type, region)
            if spot_pools:
                avg_spot = sum(p['price'] for p in spot_pools) / len(spot_pools)
                estimated_price = avg_spot * 3.0  # Rough estimate: spot is typically 60-70% cheaper
                logger.info(f"âœ“ Estimated on-demand price for {instance_type}: ${estimated_price}/hr (based on spot prices)")
                return estimated_price

            logger.error(f"Could not determine on-demand price for {instance_type}, using fallback")
            return 0.1  # Default fallback
        except Exception as e:
            logger.error(f"Failed to get on-demand price for {instance_type}: {e}", exc_info=True)
            # Try to estimate from spot
            try:
                logger.info("Attempting fallback: estimating from spot prices...")
                spot_pools = self.get_spot_pools(instance_type, region)
                if spot_pools:
                    avg_spot = sum(p['price'] for p in spot_pools) / len(spot_pools)
                    estimated_price = avg_spot * 3.0
                    logger.info(f"âœ“ Using estimated on-demand price: ${estimated_price}/hr")
                    return estimated_price
            except Exception as fallback_error:
                logger.error(f"Fallback estimation also failed: {fallback_error}")
            return 0.1
    
    def _region_to_location(self, region: str) -> str:
        """Convert region code to pricing API location name"""
        region_map = {
            'us-east-1': 'US East (N. Virginia)',
            'us-east-2': 'US East (Ohio)',
            'us-west-1': 'US West (N. California)',
            'us-west-2': 'US West (Oregon)',
            'ap-south-1': 'Asia Pacific (Mumbai)',
            'ap-northeast-1': 'Asia Pacific (Tokyo)',
            'ap-southeast-1': 'Asia Pacific (Singapore)',
            'eu-west-1': 'EU (Ireland)',
            'eu-central-1': 'EU (Frankfurt)'
        }
        return region_map.get(region, region)

# ============================================================================
# INSTANCE SWITCHER
# ============================================================================

class InstanceSwitcher:
    """FIX #9, #17: Handle instance switching with detailed timing"""
    
    def __init__(self, server_api: ServerAPI):
        self.server_api = server_api
        self.ec2 = aws_clients.ec2
        self.ec2_resource = aws_clients.ec2_resource
    
    def execute_switch(self, command: Dict, current_instance_id: str) -> bool:
        """
        Execute instance switch with detailed timing tracking
        FIX #9: Proper termination with confirmation
        FIX #17: Track all timing details
        """
        try:
            target_mode = command['target_mode']
            target_pool_id = command.get('target_pool_id')
            agent_id = command.get('agent_id')
            
            logger.info(f"Starting switch: {current_instance_id} -> {target_mode}")
            
            # Initialize timing
            timing = {
                'switch_initiated_at': datetime.utcnow().isoformat() + 'Z',
                'new_instance_ready_at': None,
                'traffic_switched_at': None,
                'old_instance_terminated_at': None
            }
            
            # Get current instance details
            current_instance = self._get_instance_details(current_instance_id)
            if not current_instance:
                logger.error("Cannot get current instance details")
                return False
            
            # Step 1: Create snapshot if enabled
            snapshot_data = {'used': False}
            if config.CREATE_SNAPSHOT_ON_SWITCH:
                snapshot_data = self._create_snapshot(current_instance)
            
            # Step 2: Launch new instance
            new_instance_id = self._launch_new_instance(
                current_instance, target_mode, target_pool_id
            )
            
            if not new_instance_id:
                logger.error("Failed to launch new instance")
                return False
            
            # Wait for new instance to be ready
            if not self._wait_for_instance_ready(new_instance_id):
                logger.error("New instance failed to start")
                self._cleanup_failed_switch(new_instance_id)
                return False
            
            timing['new_instance_ready_at'] = datetime.utcnow().isoformat() + 'Z'
            
            # Step 3: Get new instance details
            new_instance = self._get_instance_details(new_instance_id)
            
            # Step 4: Switch traffic (in real scenario, update load balancer/DNS)
            logger.info("Traffic switch point (update your load balancer/DNS here)")
            time.sleep(2)  # Simulate traffic switch
            timing['traffic_switched_at'] = datetime.utcnow().isoformat() + 'Z'
            
            # Step 5: Terminate old instance if auto-terminate enabled
            if config.AUTO_TERMINATE_OLD_INSTANCE:
                logger.info(f"Waiting {config.TERMINATE_WAIT_TIME}s before terminating old instance...")
                time.sleep(config.TERMINATE_WAIT_TIME)
                
                if self._terminate_instance(current_instance_id):
                    timing['old_instance_terminated_at'] = datetime.utcnow().isoformat() + 'Z'
                    logger.info(f"âœ“ Old instance {current_instance_id} terminated")
                else:
                    logger.warning(f"Failed to terminate old instance {current_instance_id}")
            
            # Collect pricing data for switch report
            logger.info("Collecting pricing data for switch report...")
            pricing_collector = SpotPricingCollector()

            # Get on-demand price
            on_demand_price = pricing_collector.get_ondemand_price(
                current_instance['instance_type'], config.REGION
            )
            logger.info(f"On-demand price: ${on_demand_price}/hr")

            old_price_data = {'on_demand': on_demand_price}

            # Get old instance spot price if applicable
            if current_instance.get('current_mode') == 'spot':
                old_spot_price = self._get_current_spot_price(
                    current_instance['instance_type'], current_instance['az']
                )
                old_price_data['old_spot'] = old_spot_price
                logger.info(f"Old spot price ({current_instance['az']}): ${old_spot_price}/hr")

            # Get new instance spot price if switching to spot
            if target_mode == 'spot':
                new_spot_price = self._get_current_spot_price(
                    new_instance['instance_type'], new_instance['az']
                )
                old_price_data['new_spot'] = new_spot_price
                logger.info(f"New spot price ({new_instance['az']}): ${new_spot_price}/hr")

                # Calculate savings
                if new_spot_price > 0 and on_demand_price > 0:
                    savings_pct = ((on_demand_price - new_spot_price) / on_demand_price) * 100
                    logger.info(f"ðŸ’° Estimated savings: {savings_pct:.1f}% (${on_demand_price - new_spot_price:.4f}/hr)")
            
            # Send switch report to server
            switch_report = {
                'old_instance': {
                    'instance_id': current_instance_id,
                    'instance_type': current_instance['instance_type'],
                    'region': config.REGION,
                    'az': current_instance['az'],
                    'ami_id': current_instance['ami_id'],
                    'mode': current_instance.get('current_mode', 'unknown'),
                    'pool_id': current_instance.get('current_pool_id')
                },
                'new_instance': {
                    'instance_id': new_instance_id,
                    'instance_type': new_instance['instance_type'],
                    'region': config.REGION,
                    'az': new_instance['az'],
                    'ami_id': new_instance['ami_id'],
                    'mode': target_mode,
                    'pool_id': target_pool_id
                },
                'snapshot': snapshot_data,
                'prices': old_price_data,
                'timing': timing,
                'trigger': 'manual' if command.get('priority', 0) >= 50 else 'model'
            }
            
            self.server_api.send_switch_report(agent_id, switch_report)
            
            logger.info(f"âœ“ Switch completed: {current_instance_id} -> {new_instance_id}")
            return True
            
        except Exception as e:
            logger.error(f"Switch execution failed: {e}", exc_info=True)
            return False
    
    def _get_instance_details(self, instance_id: str) -> Optional[Dict]:
        """Get instance details from AWS"""
        try:
            response = self.ec2.describe_instances(InstanceIds=[instance_id])
            
            if not response['Reservations']:
                return None
            
            instance = response['Reservations'][0]['Instances'][0]
            
            # Detect mode
            lifecycle = instance.get('InstanceLifecycle', 'normal')
            mode = 'spot' if lifecycle == 'spot' else 'ondemand'
            
            return {
                'instance_id': instance_id,
                'instance_type': instance['InstanceType'],
                'az': instance['Placement']['AvailabilityZone'],
                'ami_id': instance['ImageId'],
                'current_mode': mode,
                'current_pool_id': f"{instance['InstanceType']}.{instance['Placement']['AvailabilityZone']}" if mode == 'spot' else None
            }
        except Exception as e:
            logger.error(f"Failed to get instance details: {e}")
            return None
    
    def _create_snapshot(self, instance: Dict) -> Dict:
        """Create EBS snapshot for instance"""
        try:
            # Get root volume
            response = self.ec2.describe_volumes(
                Filters=[
                    {'Name': 'attachment.instance-id', 'Values': [instance['instance_id']]},
                    {'Name': 'attachment.device', 'Values': ['/dev/sda1', '/dev/xvda']}
                ]
            )
            
            if not response['Volumes']:
                logger.warning("No root volume found")
                return {'used': False}
            
            volume_id = response['Volumes'][0]['VolumeId']
            
            snapshot = self.ec2.create_snapshot(
                VolumeId=volume_id,
                Description=f"Spot Optimizer snapshot - {datetime.utcnow().isoformat()}"
            )
            
            snapshot_id = snapshot['SnapshotId']
            logger.info(f"âœ“ Snapshot created: {snapshot_id}")
            
            return {
                'used': True,
                'snapshot_id': snapshot_id,
                'volume_id': volume_id
            }
        except Exception as e:
            logger.error(f"Failed to create snapshot: {e}")
            return {'used': False}
    
    def _launch_new_instance(self, current_instance: Dict, target_mode: str,
                            target_pool_id: Optional[str]) -> Optional[str]:
        """Launch new instance"""
        try:
            logger.info(f"Preparing to launch {target_mode} instance...")
            logger.info(f"  AMI: {current_instance['ami_id']}")
            logger.info(f"  Instance Type: {current_instance['instance_type']}")

            launch_params = {
                'ImageId': current_instance['ami_id'],
                'InstanceType': current_instance['instance_type'],
                'MinCount': 1,
                'MaxCount': 1,
                'TagSpecifications': [{
                    'ResourceType': 'instance',
                    'Tags': [
                        {'Key': 'Name', 'Value': f"SpotOptimizer-{target_mode}"},
                        {'Key': 'ManagedBy', 'Value': 'SpotOptimizer'},
                        {'Key': 'LogicalAgentId', 'Value': config.LOGICAL_AGENT_ID}
                    ]
                }]
            }

            if target_mode == 'spot' and target_pool_id:
                # Extract AZ from pool_id
                az = target_pool_id.split('.')[-1]
                logger.info(f"  Target AZ: {az} (from pool {target_pool_id})")
                launch_params['Placement'] = {'AvailabilityZone': az}
                launch_params['InstanceMarketOptions'] = {
                    'MarketType': 'spot',
                    'SpotOptions': {
                        'SpotInstanceType': 'one-time',
                        'InstanceInterruptionBehavior': 'terminate'
                    }
                }
            elif target_mode == 'ondemand':
                logger.info(f"  Target mode: On-Demand")

            logger.info("Launching instance via EC2 API...")
            response = self.ec2.run_instances(**launch_params)

            new_instance_id = response['Instances'][0]['InstanceId']
            logger.info(f"âœ“ New instance launched successfully: {new_instance_id}")

            return new_instance_id
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', 'Unknown')
            error_msg = e.response.get('Error', {}).get('Message', str(e))
            logger.error(f"AWS API error launching instance: {error_code} - {error_msg}")
            return None
        except Exception as e:
            logger.error(f"Failed to launch instance: {e}", exc_info=True)
            return None
    
    def _wait_for_instance_ready(self, instance_id: str, timeout: int = 300) -> bool:
        """Wait for instance to be running"""
        try:
            instance = self.ec2_resource.Instance(instance_id)
            instance.wait_until_running(
                WaiterConfig={'Delay': 10, 'MaxAttempts': timeout // 10}
            )
            logger.info(f"âœ“ Instance {instance_id} is running")
            return True
        except Exception as e:
            logger.error(f"Instance failed to start: {e}")
            return False
    
    def _terminate_instance(self, instance_id: str) -> bool:
        """FIX #9: Terminate instance with confirmation"""
        try:
            self.ec2.terminate_instances(InstanceIds=[instance_id])
            logger.info(f"Termination initiated for {instance_id}")
            
            # Wait for termination
            instance = self.ec2_resource.Instance(instance_id)
            instance.wait_until_terminated(
                WaiterConfig={'Delay': 15, 'MaxAttempts': 20}
            )
            
            return True
        except Exception as e:
            logger.error(f"Failed to terminate instance: {e}")
            return False
    
    def _cleanup_failed_switch(self, instance_id: str):
        """Clean up after failed switch"""
        try:
            self.ec2.terminate_instances(InstanceIds=[instance_id])
            logger.info(f"Cleaned up failed instance: {instance_id}")
        except Exception as e:
            logger.error(f"Failed to cleanup instance: {e}")
    
    def _get_current_spot_price(self, instance_type: str, az: str) -> float:
        """Get current spot price for switch report"""
        try:
            collector = SpotPricingCollector()
            price = collector._get_spot_price(instance_type, az)
            if price is None:
                logger.warning(f"Could not fetch spot price for {instance_type} in {az}, using 0.0")
                return 0.0
            return price
        except Exception as e:
            logger.error(f"Error fetching spot price for {instance_type} in {az}: {e}")
            return 0.0

# ============================================================================
# MAIN AGENT CLASS
# ============================================================================

class SpotOptimizerAgent:
    """
    Main agent class - orchestrates all operations
    FIX #2, #6, #10, #11: Proper lifecycle management
    """
    
    def __init__(self):
        self.server_api = ServerAPI()
        self.pricing_collector = SpotPricingCollector()
        self.instance_switcher = InstanceSwitcher(self.server_api)

        # Agent state
        self.agent_id: Optional[str] = None
        self.instance_id: str = InstanceMetadata.get_instance_id()
        self.logical_agent_id: str = config.LOGICAL_AGENT_ID or self.instance_id
        self.is_running = False
        self.is_enabled = True  # FIX #10: Track enabled state

        # Pricing cache - fetched at startup for savings calculations
        self.cached_instance_type: Optional[str] = None
        self.cached_ondemand_price: Optional[float] = None

        # Threads
        self.threads: List[threading.Thread] = []

        # Shutdown event
        self.shutdown_event = threading.Event()

        logger.info(f"Agent initialized: Instance={self.instance_id}, Logical={self.logical_agent_id}")
    
    def start(self):
        """Start the agent"""
        try:
            # Register signal handlers for graceful shutdown
            signal.signal(signal.SIGINT, self._signal_handler)
            signal.signal(signal.SIGTERM, self._signal_handler)
            
            # Register agent with server
            if not self._register():
                logger.error("Failed to register agent. Exiting.")
                return

            # Fetch and cache on-demand price at startup for savings calculations
            logger.info("Fetching on-demand price for savings calculations...")
            self.cached_instance_type = InstanceMetadata.get_instance_type()
            self.cached_ondemand_price = self.pricing_collector.get_ondemand_price(
                self.cached_instance_type, config.REGION
            )
            if self.cached_ondemand_price:
                logger.info(f"âœ“ Cached on-demand price: ${self.cached_ondemand_price}/hr for {self.cached_instance_type}")
            else:
                logger.warning("Failed to cache on-demand price")

            self.is_running = True

            # Start worker threads
            self._start_workers()

            logger.info("="*80)
            logger.info("âœ“ Agent started successfully")
            logger.info(f"  Agent ID: {self.agent_id}")
            logger.info(f"  Logical ID: {self.logical_agent_id}")
            logger.info(f"  Instance: {self.instance_id}")
            logger.info(f"  Instance Type: {self.cached_instance_type}")
            logger.info(f"  On-Demand Price: ${self.cached_ondemand_price}/hr")
            logger.info(f"  Version: {config.AGENT_VERSION}")
            logger.info("="*80)
            
            # Keep main thread alive
            while self.is_running and not self.shutdown_event.is_set():
                time.sleep(1)
            
        except Exception as e:
            logger.error(f"Agent start failed: {e}", exc_info=True)
        finally:
            self._shutdown()
    
    def _register(self) -> bool:
        """
        FIX #2: Register with logical agent ID
        Prevents duplicate agent creation
        """
        try:
            # Get instance metadata
            instance_id = self.instance_id
            instance_type = InstanceMetadata.get_instance_type()
            az = InstanceMetadata.get_availability_zone()
            ami_id = InstanceMetadata.get_ami_id()
            region = config.REGION
            
            # FIX #3: Detect mode with dual verification
            current_mode, api_mode = InstanceMetadata.detect_instance_mode_dual()
            
            logger.info(f"Detected mode: {current_mode} (API verified: {api_mode})")
            
            # Registration payload with logical_agent_id
            registration_data = {
                'client_token': config.CLIENT_TOKEN,
                'hostname': config.HOSTNAME,
                'instance_id': instance_id,
                'instance_type': instance_type,
                'region': region,
                'az': az,
                'ami_id': ami_id,
                'agent_version': config.AGENT_VERSION,
                'logical_agent_id': self.logical_agent_id  # FIX #2
            }
            
            response = self.server_api.register_agent(registration_data)
            
            if not response:
                logger.error("Registration failed - no response from server")
                return False
            
            self.agent_id = response['agent_id']
            agent_config = response.get('config', {})
            
            # FIX #10: Store enabled state from config
            self.is_enabled = agent_config.get('enabled', True)
            
            logger.info(f"âœ“ Registered as agent: {self.agent_id}")
            logger.info(f"  Logical ID: {self.logical_agent_id}")
            logger.info(f"  Enabled: {self.is_enabled}")
            logger.info(f"  Auto-switch: {agent_config.get('auto_switch_enabled')}")
            logger.info(f"  Auto-terminate: {agent_config.get('auto_terminate_enabled')}")
            
            return True
            
        except Exception as e:
            logger.error(f"Registration failed: {e}", exc_info=True)
            return False
    
    def _start_workers(self):
        """Start background worker threads"""
        workers = [
            (self._heartbeat_worker, "Heartbeat"),
            (self._pending_commands_worker, "PendingCommands"),
            (self._config_refresh_worker, "ConfigRefresh"),
            (self._pricing_report_worker, "PricingReport")
        ]
        
        for worker_func, worker_name in workers:
            thread = threading.Thread(target=worker_func, name=worker_name, daemon=True)
            thread.start()
            self.threads.append(thread)
            logger.info(f"âœ“ Started worker: {worker_name}")
    
    def _heartbeat_worker(self):
        """
        FIX #6: Send accurate heartbeat with real status
        Runs every 30 seconds
        """
        logger.info("Heartbeat worker started")
        
        while self.is_running and not self.shutdown_event.is_set():
            try:
                # Determine actual status
                status = 'online' if self.is_enabled else 'disabled'
                
                # Get monitored instances (just current instance for now)
                monitored = [self.instance_id]
                
                # Send heartbeat
                success = self.server_api.send_heartbeat(
                    self.agent_id, status, monitored
                )
                
                if not success:
                    logger.warning("Heartbeat failed")
                else:
                    logger.debug(f"Heartbeat sent: status={status}")
                
            except Exception as e:
                logger.error(f"Heartbeat error: {e}")
            
            # Wait for next interval
            self.shutdown_event.wait(config.HEARTBEAT_INTERVAL)
    
    def _pending_commands_worker(self):
        """
        FIX #4, #11: Fast polling for pending commands
        Runs every 15 seconds for quick manual override response
        """
        logger.info("Pending commands worker started")
        
        while self.is_running and not self.shutdown_event.is_set():
            try:
                # FIX #10: Skip command execution if disabled
                if not self.is_enabled:
                    logger.debug("Agent disabled, skipping command check")
                    self.shutdown_event.wait(config.PENDING_COMMANDS_CHECK_INTERVAL)
                    continue
                
                # Get pending commands (sorted by priority)
                logger.debug("Checking for pending commands...")
                commands = self.server_api.get_pending_commands(self.agent_id)

                if commands:
                    logger.info(f"Found {len(commands)} pending command(s)")

                    # Execute highest priority command first
                    for command in commands:
                        try:
                            # Validate command structure
                            if not isinstance(command, dict):
                                logger.error(f"Invalid command format: {type(command)}")
                                continue

                            command_id = command.get('id')
                            if not command_id:
                                logger.error("Command missing 'id' field")
                                continue

                            target_mode = command.get('target_mode')
                            if not target_mode:
                                logger.error(f"Command {command_id} missing 'target_mode' field")
                                self.server_api.mark_command_executed(self.agent_id, command_id)
                                continue

                            priority = command.get('priority', 0)
                            target_pool_id = command.get('target_pool_id')

                            logger.info(f"Executing command {command_id}: {target_mode} (priority: {priority}, pool: {target_pool_id or 'N/A'})")

                            # Execute switch
                            success = self.instance_switcher.execute_switch(
                                {**command, 'agent_id': self.agent_id},
                                self.instance_id
                            )

                            # Mark as executed
                            mark_success = self.server_api.mark_command_executed(
                                self.agent_id, command_id
                            )
                            if not mark_success:
                                logger.warning(f"Failed to mark command {command_id} as executed on server")

                            if success:
                                logger.info(f"âœ“ Command {command_id} executed successfully")
                                # After successful switch, this instance will be terminated
                                # The new instance will start a new agent
                                if config.AUTO_TERMINATE_OLD_INSTANCE:
                                    logger.info("This instance will be terminated. Agent shutting down.")
                                    self.is_running = False
                                    break
                            else:
                                logger.error(f"âœ— Command {command_id} execution failed")

                        except KeyError as e:
                            logger.error(f"Command missing required field: {e}")
                        except Exception as e:
                            logger.error(f"Error executing command: {e}", exc_info=True)

                        # Only execute one command per cycle
                        break
                else:
                    logger.debug("No pending commands")
                
            except Exception as e:
                logger.error(f"Pending commands error: {e}", exc_info=True)
            
            # FIX #4: Fast polling (15 seconds)
            self.shutdown_event.wait(config.PENDING_COMMANDS_CHECK_INTERVAL)
    
    def _config_refresh_worker(self):
        """
        FIX #10: Periodically refresh configuration to check enabled status
        Runs every 60 seconds
        """
        logger.info("Config refresh worker started")
        
        while self.is_running and not self.shutdown_event.is_set():
            try:
                # Get current config from server
                agent_config = self.server_api.get_agent_config(self.agent_id)
                
                if agent_config:
                    new_enabled = agent_config.get('enabled', True)
                    
                    # FIX #10: Detect enable/disable toggle
                    if new_enabled != self.is_enabled:
                        logger.info(f"Agent enabled state changed: {self.is_enabled} -> {new_enabled}")
                        self.is_enabled = new_enabled
                        
                        if not self.is_enabled:
                            logger.warning("Agent disabled via server toggle")
                        else:
                            logger.info("Agent re-enabled via server toggle")
                    
                    logger.debug(f"Config refreshed: enabled={self.is_enabled}")
                else:
                    logger.warning("Failed to refresh config")
                
            except Exception as e:
                logger.error(f"Config refresh error: {e}")
            
            # Wait for next interval
            self.shutdown_event.wait(config.CONFIG_REFRESH_INTERVAL)
    
    def _pricing_report_worker(self):
        """
        FIX #3: Send pricing report with accurate mode detection
        Runs every 5 minutes
        """
        logger.info("Pricing report worker started")

        while self.is_running and not self.shutdown_event.is_set():
            try:
                # Get current instance details
                instance_type = InstanceMetadata.get_instance_type()
                az = InstanceMetadata.get_availability_zone()

                logger.info(f"Collecting pricing data for {instance_type} in {az}...")

                # FIX #3: Dual mode verification
                current_mode, api_mode = InstanceMetadata.detect_instance_mode_dual()

                # Get pricing data
                logger.debug("Fetching spot pools...")
                spot_pools = self.pricing_collector.get_spot_pools(instance_type, config.REGION)
                logger.info(f"Found {len(spot_pools)} spot pools with pricing data")

                # Use cached on-demand price if available, otherwise fetch fresh
                if self.cached_ondemand_price and self.cached_instance_type == instance_type:
                    on_demand_price = self.cached_ondemand_price
                    logger.info(f"On-demand price (cached): ${on_demand_price}/hr")
                else:
                    logger.debug("Fetching on-demand price...")
                    on_demand_price = self.pricing_collector.get_ondemand_price(instance_type, config.REGION)
                    logger.info(f"On-demand price: ${on_demand_price}/hr")
                    # Update cache
                    self.cached_ondemand_price = on_demand_price
                    self.cached_instance_type = instance_type

                # Show current spot price and savings if running on spot
                if current_mode == 'spot':
                    current_spot_price = self.pricing_collector._get_spot_price(instance_type, az)
                    if current_spot_price and on_demand_price:
                        savings_pct = ((on_demand_price - current_spot_price) / on_demand_price) * 100
                        savings_amount = on_demand_price - current_spot_price
                        logger.info(f"ðŸ’° Current spot price: ${current_spot_price}/hr | Savings: {savings_pct:.1f}% (${savings_amount:.4f}/hr)")
                    elif current_spot_price:
                        logger.info(f"Current spot price: ${current_spot_price}/hr")

                # Log spot pool prices for debugging
                if spot_pools:
                    for pool in spot_pools:
                        logger.debug(f"  Pool {pool['pool_id']}: ${pool['price']}/hr")
                else:
                    logger.warning("No spot pools found! Price data may not be available.")

                # Build report
                report = {
                    'instance': {
                        'instance_id': self.instance_id,
                        'instance_type': instance_type,
                        'region': config.REGION,
                        'az': az,
                        'current_mode': current_mode,  # FIX #3: Verified mode
                        'current_pool_id': f"{instance_type}.{az}" if current_mode == 'spot' else None
                    },
                    'on_demand_price': {
                        'price': on_demand_price
                    },
                    'spot_pools': spot_pools
                }

                # Send report
                logger.debug(f"Sending pricing report to server...")
                success = self.server_api.send_pricing_report(self.agent_id, report)

                if success:
                    logger.info(f"âœ“ Pricing report sent successfully: mode={current_mode}, {len(spot_pools)} pools, on-demand=${on_demand_price}/hr")
                else:
                    logger.error("âœ— Failed to send pricing report to server")

            except Exception as e:
                logger.error(f"Pricing report error: {e}", exc_info=True)

            # Wait for next interval
            self.shutdown_event.wait(config.PRICING_REPORT_INTERVAL)
    
    def _signal_handler(self, signum, frame):
        """Handle shutdown signals"""
        logger.info(f"Received signal {signum}, shutting down gracefully...")
        self.is_running = False
        self.shutdown_event.set()
    
    def _shutdown(self):
        """Graceful shutdown"""
        logger.info("Shutting down agent...")
        
        self.is_running = False
        self.shutdown_event.set()
        
        # Wait for threads to finish
        for thread in self.threads:
            thread.join(timeout=5)
        
        # Send final offline heartbeat
        try:
            self.server_api.send_heartbeat(self.agent_id, 'offline', [])
        except:
            pass
        
        logger.info("âœ“ Agent shutdown complete")

# ============================================================================
# ENTRY POINT
# ============================================================================

def main():
    """Main entry point"""
    logger.info("="*80)
    logger.info("AWS Spot Optimizer Agent v3.2.0")
    logger.info("="*80)
    
    # Validate configuration
    if not config.validate():
        logger.error("Configuration validation failed!")
        sys.exit(1)
    
    # Create and start agent
    agent = SpotOptimizerAgent()
    agent.start()

if __name__ == '__main__':
    main()
